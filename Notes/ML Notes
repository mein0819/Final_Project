- The machine learning model chosen at this point is Linear Regression. The purpose of this     model with this data is to predict local rent prices based off of home price data and to       understand how related they may be, and a linear relationship between the input and output     seemed to be the most logical way to explore the data. Regession analysis is highly useful     in trend forecasting, it simplifies the estimation procedure, is easier explain and           understand as far as machine learning models go, and allows control of variables to possibly   determine an unbiased relationship between two or more variables. Limitations in linear       regression include failing to capture the data properly, or underfitting, sensitivity to       outliers, and the assumption that the variables are independent, or linearly seperable.
  
- Preprocessing of the data was mostly done in the ETL phase. In a nutshell, all NaN values     were dropped from the tables, unnecessary columns were dropped and the remaining ones were 
  formatted to match for joining, rent data was plotted with possible features to show any       correlation, and the data was exported to a postgress database and joined together. 
  
- The model is connected to the database through an Amazon Web Services RDS that links to 
  pgAdmin using the sqlalchemy library. Once the table was read in and stored in a 
  DataFrame, the Date, City, and State columns were dropped. The initial test for the model
  used the %Change_Rent column for the dependent variable and the remaining columns for the 
  independent variables. This model produced a low r-squared value due to using calculated
  fields (the %Change columns). The next test dropped these features for X, leaving 
  Avg_List_Price, Avg_Sale_Price and HVI, and Avg_Rent as the dependent variable and 
  produced a much higher r-squared value.
  
- The models were initially tested using the default testing and training split of .25, 
  with the first two tests done without scaling. The third test used a standard scaler
  to scale the X features, and the fourth test used scaling on a .35 split of the test and
  train data, which was found through trial and error to see what produced the best 
  r-squared and mean squared error. 
  
- Furthur optimization for the model was attempted by adding more data, which was done by 
  extending the date range of data from the present to July 2020 to the present to 
  February 2014. This increased the rows of data from 1978 to 8500. The List Price data
  only goes back to 2018 so this data was not included in the table used for the ML model.
  The SizeRank column was left in the tables instead of being dropped as originally was done.
  After reading in the updated joined table, the SizeRank column is binned by population range
  to be used for visualizations. There was no coorelation between the size and average rent     
  within the data. Scaling was also further tested by using MinMaxScaler in addition to the    
  StandarScaler. 

- Post analysis of Deliverable 3's model coefficients revealed a higher degree of importance
  assigned to the Avg List Price variable than previously assumed so dropping that column
  was not helping the model. In addition to bringing that column back in it was decided to 
  test if adding more features would improve the model's performance. Two new datasets were 
  downloaded and imported as dataframes New Listings, and For Sale Inventory. These were put 
  through the same ETL process as the previous data and added to the model as features. Due to 
  data constraints, the final merged data set includes values from 3-31-2018 to  6-30-2022. 
  
- The model's R2 and MSE improved from .81 and 36245 to .85 and 28426 by adding 3 features back 
  into the model despite losing around 6000 rows of data. Average List Price, Average Sale Price
  and HVI were the features that influenced the model the most, with For Sale Inventory not far 
  behind the Sale Price, and New Listings having zero or a negative impact on the model, yet 
  when tested, leaving this feature out the model scores dropped so it was left in for the 
  final model.  